{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今天心情很好', '你找到你最喜欢的工作，我也很高兴。']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"shibing624/macbert4csc-base-chinese\")\n",
    "model = BertForMaskedLM.from_pretrained(\"shibing624/macbert4csc-base-chinese\")\n",
    "model.to(device)\n",
    "\n",
    "texts = [\"今天新情很好\", \"你找到你最喜欢的工作，我也很高心。\"]\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokenizer(texts, padding=True, return_tensors='pt').to(device))\n",
    "\n",
    "def get_errors(corrected_text, origin_text):\n",
    "    sub_details = []\n",
    "    for i, ori_char in enumerate(origin_text):\n",
    "        if ori_char in [' ', '“', '”', '‘', '’', '琊', '\\n', '…', '—', '擤']:\n",
    "            # add unk word\n",
    "            corrected_text = corrected_text[:i] + ori_char + corrected_text[i:]\n",
    "            continue\n",
    "        if i >= len(corrected_text):\n",
    "            continue\n",
    "        if ori_char != corrected_text[i]:\n",
    "            if ori_char.lower() == corrected_text[i]:\n",
    "                # pass english upper char\n",
    "                corrected_text = corrected_text[:i] + ori_char + corrected_text[i + 1:]\n",
    "                continue\n",
    "            sub_details.append((ori_char, corrected_text[i], i, i + 1))\n",
    "    sub_details = sorted(sub_details, key=operator.itemgetter(2))\n",
    "    return corrected_text, sub_details\n",
    "\n",
    "def get_output():\n",
    "    result = []\n",
    "    for ids, text in zip(outputs.logits, texts):\n",
    "        _text = tokenizer.decode(torch.argmax(ids, dim=-1), skip_special_tokens=True).replace(' ', '')\n",
    "        corrected_text = _text[:len(text)]\n",
    "        corrected_text, details = get_errors(corrected_text, text)\n",
    "        # print(text, ' => ', corrected_text, details)\n",
    "        result.append((corrected_text))\n",
    "    return (result)\n",
    "get_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3196968d684371006099b3d55edeef8ed90365227a30deaef86e5d4aa8519be0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
